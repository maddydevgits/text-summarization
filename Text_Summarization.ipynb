{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text-Summarization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7rns_kXpC8P",
        "outputId": "b3ef89ee-2fce-434f-f87e-247ede608ff8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from statistics import mode\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import LancasterStemmer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.layers import Input,LSTM,Embedding,Dense,Concatenate,Attention\n",
        "from sklearn.model_selection import train_test_split\n",
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puRIdsw0pq3a",
        "outputId": "5a4a66cd-17ff-4575-9363-d3f8af22860c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/text-summarization/Reviews.csv',nrows=100000)"
      ],
      "metadata": {
        "id": "Jb1ABG11peny"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(subset=['Text'],inplace=True)\n",
        "df.dropna(axis=0,inplace=True)\n",
        "input_data = df.loc[:,'Text']\n",
        "target_data = df.loc[:,'Summary']\n",
        "target_data.replace('', np.nan, inplace=True)\n",
        "\n",
        "input_texts=[]\n",
        "target_texts=[]\n",
        "input_words=[]\n",
        "target_words=[]\n",
        "contractions= pickle.load(open(\"contractions.pkl\",\"rb\"))['contractions']\n",
        "#initialize stop words and LancasterStemmer\n",
        "stop_words=set(stopwords.words('english'))\n",
        "stemm=LancasterStemmer()\n",
        "\n",
        "def clean(texts,src):\n",
        "  #remove the html tags\n",
        "  texts = BeautifulSoup(texts, \"lxml\").text\n",
        "  #tokenize the text into words \n",
        "  words=word_tokenize(texts.lower())\n",
        "  #filter words which contains \\ \n",
        "  #integers or their length is less than or equal to 3\n",
        "  words= list(filter(lambda w:(w.isalpha() and len(w)>=3),words))\n",
        "  #contraction file to expand shortened words\n",
        "  words= [contractions[w] if w in contractions else w for w in words ]\n",
        "  #stem the words to their root word and filter stop words\n",
        "  if src==\"inputs\":\n",
        "    words= [stemm.stem(w) for w in words if w not in stop_words]\n",
        "  else:\n",
        "    words= [w for w in words if w not in stop_words]\n",
        "  return words\n",
        "\n",
        "#pass the input records and taret records\n",
        "for in_txt,tr_txt in zip(input_data,target_data):\n",
        "  in_words= clean(in_txt,\"inputs\")\n",
        "  input_texts+= [' '.join(in_words)]\n",
        "  input_words+= in_words\n",
        "  #add 'sos' at start and 'eos' at end of text\n",
        "  tr_words= clean(\"sos \"+tr_txt+\" eos\",\"target\")\n",
        "  target_texts+= [' '.join(tr_words)]\n",
        "  target_words+= tr_words\n",
        "\n",
        "#store only unique words from input and target list of words\n",
        "input_words = sorted(list(set(input_words)))\n",
        "target_words = sorted(list(set(target_words)))\n",
        "num_in_words = len(input_words) #total number of input words\n",
        "num_tr_words = len(target_words) #total number of target words\n",
        "\n",
        "#get the length of the input and target texts which appears most often  \n",
        "max_in_len = mode([len(i) for i in input_texts])\n",
        "max_tr_len = mode([len(i) for i in target_texts])\n",
        "\n",
        "print(\"number of input words : \",num_in_words)\n",
        "print(\"number of target words : \",num_tr_words)\n",
        "print(\"maximum input length : \",max_in_len)\n",
        "print(\"maximum target length : \",max_tr_len)\n",
        "\n",
        "\n",
        "#split the input and target text into 80:20 ratio or testing size of 20%.\n",
        "x_train,x_test,y_train,y_test=train_test_split(input_texts,target_texts,test_size=0.2,random_state=0)\n",
        "\n",
        "#train the tokenizer with all the words\n",
        "in_tokenizer = Tokenizer()\n",
        "in_tokenizer.fit_on_texts(x_train)\n",
        "tr_tokenizer = Tokenizer()\n",
        "tr_tokenizer.fit_on_texts(y_train)\n",
        "\n",
        "#convert text into sequence of integers\n",
        "#where the integer will be the index of that word\n",
        "x_train= in_tokenizer.texts_to_sequences(x_train) \n",
        "y_train= tr_tokenizer.texts_to_sequences(y_train) \n",
        "\n",
        "#pad array of 0's if the length is less than the maximum length \n",
        "en_in_data= pad_sequences(x_train,  maxlen=max_in_len, padding='post') \n",
        "dec_data= pad_sequences(y_train,  maxlen=max_tr_len, padding='post')\n",
        "\n",
        "#decoder input data will not include the last word \n",
        "#i.e. 'eos' in decoder input data\n",
        "dec_in_data = dec_data[:,:-1]\n",
        "#decoder target data will be one time step ahead as it will not include\n",
        "# the first word i.e 'sos'\n",
        "dec_tr_data = dec_data.reshape(len(dec_data),max_tr_len,1)[:,1:]\n",
        "\n",
        "K.clear_session() \n",
        "latent_dim = 500\n",
        "\n",
        "#create input object of total number of input words\n",
        "en_inputs = Input(shape=(max_in_len,)) \n",
        "en_embedding = Embedding(num_in_words+1, latent_dim)(en_inputs) \n",
        "\n",
        "#create 3 stacked LSTM layer with the shape of hidden dimension\n",
        "#LSTM 1\n",
        "en_lstm1= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "en_outputs1, state_h1, state_c1= en_lstm1(en_embedding) \n",
        "\n",
        "#LSTM2\n",
        "en_lstm2= LSTM(latent_dim, return_state=True, return_sequences=True) \n",
        "en_outputs2, state_h2, state_c2= en_lstm2(en_outputs1) \n",
        "\n",
        "#LSTM3\n",
        "en_lstm3= LSTM(latent_dim,return_sequences=True,return_state=True)\n",
        "en_outputs3 , state_h3 , state_c3= en_lstm3(en_outputs2)\n",
        "\n",
        "#encoder states\n",
        "en_states= [state_h3, state_c3]\n",
        "\n",
        "# Decoder. \n",
        "dec_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(num_tr_words+1, latent_dim) \n",
        "dec_embedding = dec_emb_layer(dec_inputs) \n",
        "\n",
        "#initialize decoder's LSTM layer with the output states of encoder\n",
        "dec_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "dec_outputs, *_ = dec_lstm(dec_embedding,initial_state=en_states) \n",
        "\n",
        "#Attention layer\n",
        "attention =Attention()\n",
        "attn_out = attention([dec_outputs,en_outputs3])\n",
        "\n",
        "#Concatenate the attention output with the decoder ouputs\n",
        "merge=Concatenate(axis=-1, name='concat_layer1')([dec_outputs,attn_out])\n",
        "\n",
        "#Dense layer (output layer)\n",
        "dec_dense = Dense(num_tr_words+1, activation='softmax') \n",
        "dec_outputs = dec_dense(merge) \n",
        "\n",
        "#Mode class and model summary\n",
        "model = Model([en_inputs, dec_inputs], dec_outputs) \n",
        "model.summary()\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "\n",
        "model.compile( \n",
        "    optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"] ) \n",
        "model.fit( \n",
        "    [en_in_data, dec_in_data],\n",
        "    dec_tr_data, \n",
        "    batch_size=512, \n",
        "    epochs=10, \n",
        "    validation_split=0.1,\n",
        "    )\n",
        "\n",
        "#Save model\n",
        "model.save(\"s2s\")\n",
        "\n",
        "# encoder inference\n",
        "latent_dim=500\n",
        "#load the model\n",
        "model = models.load_model(\"s2s\")\n",
        "\n",
        "#construct encoder model from the output of 6 layer i.e.last LSTM layer\n",
        "en_outputs,state_h_enc,state_c_enc = model.layers[6].output\n",
        "en_states=[state_h_enc,state_c_enc]\n",
        "#add input and state from the layer.\n",
        "en_model = Model(model.input[0],[en_outputs]+en_states)\n",
        "\n",
        "# decoder inference\n",
        "#create Input object for hidden and cell state for decoder\n",
        "#shape of layer with hidden or latent dimension\n",
        "dec_state_input_h = Input(shape=(latent_dim,))\n",
        "dec_state_input_c = Input(shape=(latent_dim,))\n",
        "dec_hidden_state_input = Input(shape=(max_in_len,latent_dim))\n",
        "\n",
        "# Get the embeddings and input layer from the model\n",
        "dec_inputs = model.input[1]\n",
        "dec_emb_layer = model.layers[5]\n",
        "dec_lstm = model.layers[7]\n",
        "dec_embedding= dec_emb_layer(dec_inputs)\n",
        "\n",
        "#add input and initialize LSTM layer with encoder LSTM states.\n",
        "dec_outputs2, state_h2, state_c2 = dec_lstm(dec_embedding, initial_state=[dec_state_input_h,dec_state_input_c])\n",
        "\n",
        "#Attention layer\n",
        "attention = model.layers[8]\n",
        "attn_out2 = attention([dec_outputs2,dec_hidden_state_input])\n",
        "\n",
        "merge2 = Concatenate(axis=-1)([dec_outputs2, attn_out2])\n",
        "\n",
        "#Dense layer\n",
        "dec_dense = model.layers[10]\n",
        "dec_outputs2 = dec_dense(merge2)\n",
        "\n",
        "# Finally define the Model Class\n",
        "dec_model = Model(\n",
        "[dec_inputs] + [dec_hidden_state_input,dec_state_input_h,dec_state_input_c],\n",
        "[dec_outputs2] + [state_h2, state_c2])\n",
        "\n",
        "#create a dictionary with a key as index and value as words.\n",
        "reverse_target_word_index = tr_tokenizer.index_word\n",
        "reverse_source_word_index = in_tokenizer.index_word\n",
        "target_word_index = tr_tokenizer.word_index\n",
        "reverse_target_word_index[0]=' '\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    #get the encoder output and states by passing the input sequence\n",
        "    en_out, en_h, en_c= en_model.predict(input_seq)\n",
        "\n",
        "    #target sequence with inital word as 'sos'\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    target_seq[0, 0] = target_word_index['sos']\n",
        "\n",
        "    #if the iteration reaches the end of text than it will be stop the iteration\n",
        "    stop_condition = False\n",
        "    #append every predicted word in decoded sentence\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition: \n",
        "        #get predicted output, hidden and cell state.\n",
        "        output_words, dec_h, dec_c= dec_model.predict([target_seq] + [en_out,en_h, en_c])\n",
        "        \n",
        "        #get the index and from the dictionary get the word for that index.\n",
        "        word_index = np.argmax(output_words[0, -1, :])\n",
        "        text_word = reverse_target_word_index[word_index]\n",
        "        decoded_sentence += text_word +\" \"\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find a stop word or last word.\n",
        "        if text_word == \"eos\" or len(decoded_sentence) > max_tr_len:\n",
        "          stop_condition = True\n",
        "        \n",
        "        #update target sequence to the current word index.\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] = word_index\n",
        "        en_h, en_c = dec_h, dec_c\n",
        "    \n",
        "    #return the deocded sentence\n",
        "    return decoded_sentence\n",
        "\n",
        "inp_review = input(\"Enter : \")\n",
        "print(\"Review :\",inp_review)\n",
        "\n",
        "inp_review = clean(inp_review,\"inputs\")\n",
        "inp_review = ' '.join(inp_review)\n",
        "inp_x= in_tokenizer.texts_to_sequences([inp_review]) \n",
        "inp_x= pad_sequences(inp_x,  maxlen=max_in_len, padding='post')\n",
        "\n",
        "summary=decode_sequence(inp_x.reshape(1,max_in_len))\n",
        "if 'eos' in summary :\n",
        "  summary=summary.replace('eos','')\n",
        "print(\"\\nPredicted summary:\",summary);print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhdYeXNcp_Ym",
        "outputId": "3261339a-b4ab-46c9-8571-b580e34175c3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of input words :  32131\n",
            "number of target words :  14157\n",
            "maximum input length :  74\n",
            "maximum target length :  17\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 74)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 74, 500)      16066000    ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 74, 500),    2002000     ['embedding[0][0]']              \n",
            "                                 (None, 500),                                                     \n",
            "                                 (None, 500)]                                                     \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, 74, 500),    2002000     ['lstm[0][0]']                   \n",
            "                                 (None, 500),                                                     \n",
            "                                 (None, 500)]                                                     \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 500)    7079000     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm_2 (LSTM)                  [(None, 74, 500),    2002000     ['lstm_1[0][0]']                 \n",
            "                                 (None, 500),                                                     \n",
            "                                 (None, 500)]                                                     \n",
            "                                                                                                  \n",
            " lstm_3 (LSTM)                  [(None, None, 500),  2002000     ['embedding_1[0][0]',            \n",
            "                                 (None, 500),                     'lstm_2[0][1]',                 \n",
            "                                 (None, 500)]                     'lstm_2[0][2]']                 \n",
            "                                                                                                  \n",
            " attention (Attention)          (None, None, 500)    0           ['lstm_3[0][0]',                 \n",
            "                                                                  'lstm_2[0][0]']                 \n",
            "                                                                                                  \n",
            " concat_layer1 (Concatenate)    (None, None, 1000)   0           ['lstm_3[0][0]',                 \n",
            "                                                                  'attention[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 14158)  14172158    ['concat_layer1[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 45,325,158\n",
            "Trainable params: 45,325,158\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "125/125 [==============================] - 65s 421ms/step - loss: 1.5305 - accuracy: 0.8110 - val_loss: 1.2838 - val_accuracy: 0.8344\n",
            "Epoch 2/10\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 1.2631 - accuracy: 0.8333 - val_loss: 1.2298 - val_accuracy: 0.8367\n",
            "Epoch 3/10\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 1.1959 - accuracy: 0.8364 - val_loss: 1.1882 - val_accuracy: 0.8387\n",
            "Epoch 4/10\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 1.1441 - accuracy: 0.8383 - val_loss: 1.1515 - val_accuracy: 0.8401\n",
            "Epoch 5/10\n",
            "125/125 [==============================] - 51s 407ms/step - loss: 1.0956 - accuracy: 0.8400 - val_loss: 1.1315 - val_accuracy: 0.8406\n",
            "Epoch 6/10\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 1.0553 - accuracy: 0.8417 - val_loss: 1.1196 - val_accuracy: 0.8411\n",
            "Epoch 7/10\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 1.0190 - accuracy: 0.8434 - val_loss: 1.1053 - val_accuracy: 0.8420\n",
            "Epoch 8/10\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.9851 - accuracy: 0.8451 - val_loss: 1.1015 - val_accuracy: 0.8416\n",
            "Epoch 9/10\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.9528 - accuracy: 0.8467 - val_loss: 1.0948 - val_accuracy: 0.8425\n",
            "Epoch 10/10\n",
            "125/125 [==============================] - 51s 406ms/step - loss: 0.9207 - accuracy: 0.8484 - val_loss: 1.0951 - val_accuracy: 0.8423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7b2d348450> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7b2d4afc10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7b2cf84f10> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f7b2d983050> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter : Narendra Modi is the Prime Minister of India since 2014 and he elected twice\n",
            "Review : Narendra Modi is the Prime Minister of India since 2014 and he elected twice\n",
            "\n",
            "Predicted summary: great product  \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_review = input(\"Enter : \")\n",
        "print(\"Review :\",inp_review)\n",
        "\n",
        "inp_review = clean(inp_review,\"inputs\")\n",
        "inp_review = ' '.join(inp_review)\n",
        "inp_x= in_tokenizer.texts_to_sequences([inp_review]) \n",
        "inp_x= pad_sequences(inp_x,  maxlen=max_in_len, padding='post')\n",
        "\n",
        "summary=decode_sequence(inp_x.reshape(1,max_in_len))\n",
        "if 'eos' in summary :\n",
        "  summary=summary.replace('eos','')\n",
        "print(\"\\nPredicted summary:\",summary);print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igaelJIXyrjB",
        "outputId": "d1698617-c4d0-4640-e37c-86f2863c9b20"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter : I love the taste of the Republic of Tea teas and I love the fact that they are surgar\n",
            "Review : I love the taste of the Republic of Tea teas and I love the fact that they are surgar\n",
            "\n",
            "Predicted summary: great tea  \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}